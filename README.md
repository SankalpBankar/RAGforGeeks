# ğŸ“šRAGforGeeks ğŸ¤–ğŸ” ğŸ‘“
A powerful Retrieval-Augmented Generation (RAG) assistant designed to provide accurate and contextual answers from GeeksforGeeks Nation SkillUp content.

ğŸ“ Project Directory Structure ğŸ§ ğŸ’¬
RAGforGeeks-ChatBot/

â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ models/                   # Store downloaded LLM (e.g., LLaMA2) ğŸ§ 
â”‚   â”œâ”€â”€ vectorstores/            # Vector DB for storing embeddings ğŸ“¦
â”‚   â”‚   â””â”€â”€ db_faiss/            # FAISS index files ğŸ“
â”‚   â”œâ”€â”€ model.py                 # LLM + retrieval logic using LangChain ğŸ› ï¸
â”‚   â”œâ”€â”€ initialize_faiss.py      # FAISS setup script âš™ï¸
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                   # Streamlit UI for chatbot ğŸ’»
â”‚
â”œâ”€â”€ setup.txt                    # LLM model setup instructions ğŸ“
â”œâ”€â”€ requirements.txt             # Python dependencies ğŸ“¦
â”œâ”€â”€ README.md                    # Project overview ğŸ“˜




ğŸ’¡ Tech Stack ğŸ› ï¸
â€¢	Python ğŸ (Core programming language for backend logic)
â€¢	Llama 2 (GGML) ğŸ¦™ (Large Language Model used for answering queries locally)
â€¢	LangChain ğŸ”— (Framework for implementing RAG â€” Retrieval Augmented Generation)
â€¢	FAISS ğŸ” (For storing and searching vector embeddings efficiently)
â€¢	ChromaDB ğŸ—‚ï¸ (Optional vector store library used by LangChain)
â€¢	CTransformers âš¡ (Lightweight LLM inference for GGML models)
â€¢	Streamlit ğŸŒ (Frontend UI framework to interact with the chatbot)
â€¢	Groq API ğŸš€ (For high-speed LLM inference using GroqCloud)
â€¢	dotenv ğŸ” (To manage API keys securely via environment variables)


âš™ï¸ Setup & Installation for RAGforGeeks ğŸ§ ğŸ’¬
Follow these steps to set up and run your RAG-based chatbot:

1ï¸âƒ£ Clone the Repository ğŸ“¥
git clone https://github.com/SankalpBankar/RAGforGeeks.git
cd RAGforGeeks

2ï¸âƒ£ Install Dependencies ğŸ“¦
Ensure you're using Python 3.9+, then install all required libraries:
pip install langchain groq chromadb tiktoken langchain-groq langchain-community pymupdf

3ï¸âƒ£ Configure Environment ğŸ”
Set your GROQ API key securely using an environment variable:
import os
os.environ["GROQ_API_KEY"] = "your-groq-api-key"
(Or use .env with python-dotenv if running locally.)

4ï¸âƒ£ Load the LLM (LLaMA3) ğŸ¦™
The code uses LangChain + Groq to load the model:
from langchain_groq import ChatGroq
llm = ChatGroq(
    groq_api_key=os.environ["GROQ_API_KEY"],
    model_name="llama3-8b-8192"
)
5ï¸âƒ£ Run Your Application ğŸš€
Ensure you have all backend files and Streamlit app ready. Then run:
streamlit run app.py

ğŸ› ï¸ Troubleshooting ğŸš¨
â€¢	API Key Error
Set your key using: 
os.environ["GROQ_API_KEY"] = "your-api-key"

â€¢	FAISS Index Empty or Missing
Run the initialize_faiss.py script to embed and store documents.






