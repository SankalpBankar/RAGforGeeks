# ğŸ“šRAGforGeeks ğŸ¤–ğŸ” ğŸ‘“\n
A powerful Retrieval-Augmented Generation (RAG) assistant designed to provide accurate and contextual answers from GeeksforGeeks Nation SkillUp content.\n


##ğŸ“ Project Directory Structure ğŸ§ ğŸ’¬\n\n
RAGforGeeks-ChatBot/

â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ models/                   # Store downloaded LLM (e.g., LLaMA2) ğŸ§ \n
â”‚   â”œâ”€â”€ vectorstores/            # Vector DB for storing embeddings ğŸ“¦\n
â”‚   â”‚   â””â”€â”€ db_faiss/            # FAISS index files ğŸ“\n
â”‚   â”œâ”€â”€ model.py                 # LLM + retrieval logic using LangChain ğŸ› ï¸\n
â”‚   â”œâ”€â”€ initialize_faiss.py      # FAISS setup script âš™ï¸\n
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                   # Streamlit UI for chatbot ğŸ’»\n
â”‚
â”œâ”€â”€ setup.txt                    # LLM model setup instructions ğŸ“\n
â”œâ”€â”€ requirements.txt             # Python dependencies ğŸ“¦\n
â”œâ”€â”€ README.md                    # Project overview ğŸ“˜\n


##ğŸ’¡ Tech Stack ğŸ› ï¸\n
â€¢	Python ğŸ (Core programming language for backend logic)\n
â€¢	Llama 2 (GGML) ğŸ¦™ (Large Language Model used for answering queries locally)\n
â€¢	LangChain ğŸ”— (Framework for implementing RAG â€” Retrieval Augmented Generation)\n
â€¢	FAISS ğŸ” (For storing and searching vector embeddings efficiently)\n
â€¢	ChromaDB ğŸ—‚ï¸ (Optional vector store library used by LangChain)\n
â€¢	CTransformers âš¡ (Lightweight LLM inference for GGML models)\n
â€¢	Streamlit ğŸŒ (Frontend UI framework to interact with the chatbot)\n
â€¢	Groq API ğŸš€ (For high-speed LLM inference using GroqCloud)\n
â€¢	dotenv ğŸ” (To manage API keys securely via environment variables)\n


##âš™ï¸ Setup & Installation for RAGforGeeks ğŸ§ ğŸ’¬\n
Follow these steps to set up and run your RAG-based chatbot:\n
1ï¸âƒ£ Clone the Repository ğŸ“¥\n
git clone https://github.com/SankalpBankar/RAGforGeeks.git\n
cd RAGforGeeks\n

2ï¸âƒ£ Install Dependencies ğŸ“¦\n
Ensure you're using Python 3.9+, then install all required libraries:\n
pip install langchain groq chromadb tiktoken langchain-groq langchain-community pymupdf\n

3ï¸âƒ£ Configure Environment ğŸ”\n
Set your GROQ API key securely using an environment variable:\n
import os\n
os.environ["GROQ_API_KEY"] = "your-groq-api-key"\n
(Or use .env with python-dotenv if running locally.)\n

4ï¸âƒ£ Load the LLM (LLaMA3) ğŸ¦™\n
The code uses LangChain + Groq to load the model:\n
from langchain_groq import ChatGroq\n
llm = ChatGroq(\n
    groq_api_key=os.environ["GROQ_API_KEY"],\n
    model_name="llama3-8b-8192"\n
)\n

5ï¸âƒ£ Run Your Application ğŸš€\n
Ensure you have all backend files and Streamlit app ready. Then run:\n
streamlit run app.py\n

##ğŸ› ï¸ Troubleshooting ğŸš¨\n
â€¢	API Key Error\n
Set your key using:\n 
os.environ["GROQ_API_KEY"] = "your-api-key"\n

â€¢	FAISS Index Empty or Missing\n
Run the initialize_faiss.py script to embed and store documents.\n






